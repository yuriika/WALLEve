namespace WALLEve.Services.AI.Interfaces;

/// <summary>
/// Service f端r Ollama AI Integration
/// Kommuniziert mit lokaler Ollama Installation
/// </summary>
public interface IOllamaService
{
    /// <summary>
    /// Generiert Text basierend auf einem Prompt
    /// </summary>
    Task<string> GenerateAsync(string prompt, object? context = null, string? model = null);

    /// <summary>
    /// Generiert und parsed JSON-Response
    /// </summary>
    Task<T?> GenerateJsonAsync<T>(string prompt, object? context = null, string? model = null);

    /// <summary>
    /// Pr端ft ob Ollama verf端gbar ist
    /// </summary>
    Task<bool> IsAvailableAsync();

    /// <summary>
    /// Listet verf端gbare Modelle
    /// </summary>
    Task<List<string>?> GetAvailableModelsAsync();
}
